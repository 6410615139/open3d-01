{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e250307-d14e-4ee2-9217-528ed04c0bdb",
   "metadata": {},
   "source": [
    "# [Tutorials ในส่วนของ point cloud](https://www.open3d.org/docs/release/tutorial/geometry/pointcloud.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19304cb-e94a-4511-9608-63538c9d0b75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "print(o3d.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cd2b71-af89-4bba-b953-78756827598a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34mDataset\u001b[0m\n",
      "│   ├── \u001b[00miphone7.ply\u001b[0m\n",
      "│   └── \u001b[00mkota_circuit2.ply\u001b[0m\n",
      "├── \u001b[00mREADME.md\u001b[0m\n",
      "└── \u001b[00mclip2.ipynb\u001b[0m\n",
      "\n",
      "2 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "!tree . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247ab7e-e313-4179-9e5c-cffd38050e50",
   "metadata": {},
   "source": [
    "# What is a PLY file? \n",
    "\n",
    "PLY, Polygon File Format, represents 3D file format that stores graphical objects described as a collection of polygons. The purpose of this file format was to establish a simple and easy file type that is general enough to be useful for a wide range of models. PLY file format comes as ASCII as well as Binary format for compact storage and for rapid saving and loading. The file format is used by different applications that provide support for 3D files reading.\n",
    "\n",
    "[Reference](https://docs.fileformat.com/3d/ply/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5215312-11f5-4f42-b837-949e257cc547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_iphone7_ply = \"Dataset/iphone7.ply\"\n",
    "path_kota_circuit2_ply = \"Dataset/kota_circuit2.ply\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9778c3-a706-4b86-bb1d-4f86c262a3ec",
   "metadata": {},
   "source": [
    "# Load a ply point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cda061d-049e-46e3-aca6-cfc5c51b74c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n",
      "iphone7:\n",
      " PointCloud with 8076963 points.\n",
      "kota_circuit2:\n",
      " PointCloud with 14640197 points.\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "# ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "# pcd = o3d.io.read_point_cloud(ply_point_cloud.path)\n",
    "pcd_iphone7 = o3d.io.read_point_cloud(path_iphone7_ply)\n",
    "pcd_kota_circuit2 = o3d.io.read_point_cloud(path_kota_circuit2_ply)\n",
    "print(\"iphone7:\\n\",pcd_iphone7)\n",
    "print(\"kota_circuit2:\\n\",pcd_kota_circuit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf92bfda-0a2f-4167-b2b7-505da120025e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone7:\n",
      " [[-1033.32434082  1316.9284668  -1062.46020508]\n",
      " [-1022.46795654  1315.88684082 -1062.16821289]\n",
      " [-1011.65161133  1314.84265137 -1061.86083984]\n",
      " ...\n",
      " [15163.73046875  4870.33691406  -860.22692871]\n",
      " [15154.33007812  4861.89550781  -859.56201172]\n",
      " [15145.42675781  4854.18017578  -859.59936523]]\n",
      "kota_circuit2:\n",
      " [[  82.07930756 -147.18885803  -78.15903473]\n",
      " [  97.60070801  149.98822021  -53.49351883]\n",
      " [  70.49710846 -229.24028015  -78.54177856]\n",
      " ...\n",
      " [  26.64775658  -36.49408722  -89.59648132]\n",
      " [ -88.472229     49.91682816  -75.39753723]\n",
      " [ -23.17474937  335.25888062 -102.58750916]]\n"
     ]
    }
   ],
   "source": [
    "points_iphone7 = np.asarray(pcd_iphone7.points)\n",
    "points_kota_circuit2 = np.asarray(pcd_kota_circuit2.points)\n",
    "print(\"iphone7:\\n\",points_iphone7)\n",
    "print(\"kota_circuit2:\\n\",points_kota_circuit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d25a1-dffd-4e03-a3d6-672e9471f45d",
   "metadata": {},
   "source": [
    "# Visualize point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725cbdb2-fc2e-46a9-849c-08ab317096f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([pcd_iphone7],\n",
    "#                                   zoom=0.3412,\n",
    "#                                   front=[0.4257, -0.2125, -0.8795],\n",
    "#                                   lookat=[2.6172, 2.0475, 1.532],\n",
    "#                                   up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f6ebd7-755e-4086-8113-e2aab61c0eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([pcd_kota_circuit2],\n",
    "#                                   zoom=0.3412,\n",
    "#                                   front=[0.4257, -0.2125, -0.8795],\n",
    "#                                   lookat=[2.6172, 2.0475, 1.532],\n",
    "#                                   up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e0537-293a-4903-a13b-48eca56204ec",
   "metadata": {},
   "source": [
    "# Voxel downsampling\n",
    "\n",
    "Voxel downsampling uses a regular voxel grid to create a uniformly downsampled point cloud from an input point cloud. It is often used as a pre-processing step for many point cloud processing tasks. The algorithm operates in two steps:\n",
    "\n",
    "1. Points are bucketed into voxels.\n",
    "2. Each occupied voxel generates exactly one point by averaging all points inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ece6cf-cdac-4731-9413-6b7e338b4852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample the point cloud with a voxel of 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Downsample the point cloud with a voxel of 0.05\")\n",
    "downpcd_iphone7 = pcd_iphone7.voxel_down_sample(voxel_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af548e44-4804-47e9-a702-fe8c4fda555b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample the point cloud with a voxel of 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Downsample the point cloud with a voxel of 0.05\")\n",
    "downpcd_kota_circuit2 = pcd_kota_circuit2.voxel_down_sample(voxel_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae91fbc-1bf2-4c17-b95f-27c50fa9240f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbff4f05-a6ed-49c3-a1be-9bbb22d3098a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pcd_only_number(pcd):\n",
    "    return int(str(pcd).split()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b33949c-22fc-433c-a267-3d942cdf3286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌─────────┬─────────┬──────────┐\n",
      "│         ┆ iphone7 ┆ kota     │\n",
      "│ ---     ┆ ---     ┆ ---      │\n",
      "│ str     ┆ i64     ┆ i64      │\n",
      "╞═════════╪═════════╪══════════╡\n",
      "│ pcd     ┆ 8076963 ┆ 14640197 │\n",
      "│ downpcd ┆ 8076935 ┆ 14246787 │\n",
      "│ diff    ┆ 28      ┆ 393410   │\n",
      "└─────────┴─────────┴──────────┘\n",
      "3.466649531513268e-06\n",
      "0.026871906163557772\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"\" : [\"pcd\", \"downpcd\", \"diff\"],\n",
    "    \"iphone7\" : [pcd_only_number(pcd_iphone7), pcd_only_number(downpcd_iphone7), (pcd_only_number(pcd_iphone7)-pcd_only_number(downpcd_iphone7))],\n",
    "    \"kota\" : [pcd_only_number(pcd_kota_circuit2), pcd_only_number(downpcd_kota_circuit2), (pcd_only_number(pcd_kota_circuit2)-pcd_only_number(downpcd_kota_circuit2))],\n",
    "}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "print(28/8076963)\n",
    "print(393410/14640197)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba4640-f69f-4e3a-922a-34f49f8b58fe",
   "metadata": {},
   "source": [
    "# Visualize downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d74b549-a96b-46f6-8a77-65b27e3f76be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([downpcd_iphone7],\n",
    "#                                   zoom=0.3412,\n",
    "#                                   front=[0.4257, -0.2125, -0.8795],\n",
    "#                                   lookat=[2.6172, 2.0475, 1.532],\n",
    "#                                   up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "384e2f77-77b5-4fb2-8d86-a73105e1504b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([downpcd_kota_circuit2],\n",
    "#                                   zoom=0.3412,\n",
    "#                                   front=[0.4257, -0.2125, -0.8795],\n",
    "#                                   lookat=[2.6172, 2.0475, 1.532],\n",
    "#                                   up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a924ebc-2f78-4958-8322-238f0320a716",
   "metadata": {},
   "source": [
    "# Vertex normal estimation\n",
    "\n",
    "Another basic operation for point cloud is point normal estimation. Press N to see point normals. The keys - and + can be used to control the length of the normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4506179c-3839-4c40-9a91-dfb833d52dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompute the normal of the downsampled point cloud\n"
     ]
    }
   ],
   "source": [
    "print(\"Recompute the normal of the downsampled point cloud\")\n",
    "downpcd_iphone7.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8005cd1-4be8-44a4-bb0c-8c55349e20fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompute the normal of the downsampled point cloud\n"
     ]
    }
   ],
   "source": [
    "print(\"Recompute the normal of the downsampled point cloud\")\n",
    "downpcd_kota_circuit2.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7387bfd-cee1-4934-b3e4-c76707805640",
   "metadata": {},
   "source": [
    "# Visualize normal estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79576f5b-bf24-4be9-9d1b-3e36af58279a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([downpcd_iphone7],\n",
    "#                                   zoom=0.3412,\n",
    "#                                   front=[0.4257, -0.2125, -0.8795],\n",
    "#                                   lookat=[2.6172, 2.0475, 1.532],\n",
    "#                                   up=[-0.0694, -0.9768, 0.2024],\n",
    "#                                   point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd051b-e544-4a1e-87d5-96c543525b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([downpcd_kota_circuit2],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
    "                                  point_show_normal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87edcb-a680-4529-9e10-95d8ad15838a",
   "metadata": {},
   "source": [
    "# Access estimated vertex normal\n",
    "\n",
    "Estimated normal vectors can be retrieved from the normals variable of downpcd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75a4caeb-0810-4f34-aa4c-8e5f439342bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a normal vector of the 0th point\n",
      "[0. 0. 1.]\n",
      "Print a normal vector of the 0th point\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print a normal vector of the 0th point\")\n",
    "print(downpcd_iphone7.normals[0])\n",
    "print(\"Print a normal vector of the 0th point\")\n",
    "print(downpcd_kota_circuit2.normals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea13841-3b6a-46ce-844a-fed9f068aabf",
   "metadata": {
    "tags": []
   },
   "source": [
    "To check out other variables, please use help(downpcd). Normal vectors can be transformed as a numpy array using np.asarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e3be405-aa05-447c-b28b-bbb33e7ed70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the normal vectors of the first 10 points\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Print the normal vectors of the first 10 points\n",
      "[[ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [-0.70574554  0.70522761 -0.06765539]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.83193173  0.19213863 -0.52055004]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [-0.3815197  -0.71594861 -0.58468821]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.01626067 -0.36616579 -0.93040755]\n",
      " [ 0.81908598  0.48168866  0.31156731]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print the normal vectors of the first 10 points\")\n",
    "print(np.asarray(downpcd_iphone7.normals)[:7, :])\n",
    "print(\"Print the normal vectors of the first 10 points\")\n",
    "print(np.asarray(downpcd_kota_circuit2.normals)[:20, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9211e9-8101-47da-8991-a3ddd95cf98c",
   "metadata": {},
   "source": [
    "# Crop point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db43f31-31b8-4e8f-a367-eede5513833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load a polygon volume and use it to crop the original point cloud\")\n",
    "demo_crop_data = o3d.data.DemoCropPointCloud()\n",
    "pcd = o3d.io.read_point_cloud(demo_crop_data.point_cloud_path)\n",
    "vol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\n",
    "chair = vol.crop_point_cloud(pcd)\n",
    "o3d.visualization.draw_geometries([chair],\n",
    "                                  zoom=0.7,\n",
    "                                  front=[0.5439, -0.2333, -0.8060],\n",
    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
    "                                  up=[-0.1781, -0.9708, 0.1608])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e091269-2613-4285-ae7b-a1d381d286bc",
   "metadata": {},
   "source": [
    "# Paint point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd710fc-7062-406f-8d4e-92ffe3d45d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Paint chair\")\n",
    "chair.paint_uniform_color([1, 0.706, 0])\n",
    "o3d.visualization.draw_geometries([chair],\n",
    "                                  zoom=0.7,\n",
    "                                  front=[0.5439, -0.2333, -0.8060],\n",
    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
    "                                  up=[-0.1781, -0.9708, 0.1608])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c0787f-36cc-4176-9bb0-bcd84e9f6fa2",
   "metadata": {},
   "source": [
    "# Point cloud distance\n",
    "\n",
    "Open3D provides the method compute_point_cloud_distance to compute the distance from a source point cloud to a target point cloud. I.e., it computes for each point in the source point cloud the distance to the closest point in the target point cloud.\n",
    "\n",
    "In the example below we use the function to compute the difference between two point clouds. Note that this method could also be used to compute the Chamfer distance between two point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb3e5bc-2c24-4431-b636-81aef4fa36d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "demo_crop_data = o3d.data.DemoCropPointCloud()\n",
    "pcd = o3d.io.read_point_cloud(demo_crop_data.point_cloud_path)\n",
    "vol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\n",
    "chair = vol.crop_point_cloud(pcd_iphone7)\n",
    "\n",
    "dists = pcd.compute_point_cloud_distance(chair)\n",
    "dists = np.asarray(dists)\n",
    "ind = np.where(dists > 0.01)[0]\n",
    "pcd_without_chair = pcd.select_by_index(ind)\n",
    "o3d.visualization.draw_geometries([pcd_without_chair],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40801300-26d9-4e5b-a6c6-56a01af9f4c3",
   "metadata": {},
   "source": [
    "# Bounding volumes\n",
    "The PointCloud geometry type has bounding volumes as all other geometry types in Open3D. Currently, Open3D implements an AxisAlignedBoundingBox and an OrientedBoundingBox that can also be used to crop the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b076b-a39e-4afd-a1fd-302b36579553",
   "metadata": {},
   "outputs": [],
   "source": [
    "aabb = chair.get_axis_aligned_bounding_box()\n",
    "aabb.color = (1, 0, 0)\n",
    "obb = chair.get_oriented_bounding_box()\n",
    "obb.color = (0, 1, 0)\n",
    "o3d.visualization.draw_geometries([chair, aabb, obb],\n",
    "                                  zoom=0.7,\n",
    "                                  front=[0.5439, -0.2333, -0.8060],\n",
    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
    "                                  up=[-0.1781, -0.9708, 0.1608])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71e595-5b56-43a0-86f5-ca4c987d9926",
   "metadata": {},
   "source": [
    "# Convex hull\n",
    "The convex hull of a point cloud is the smallest convex set that contains all points. Open3D contains the method compute_convex_hull that computes the convex hull of a point cloud. The implementation is based on Qhull.\n",
    "\n",
    "In the example code below we first sample a point cloud from a mesh and compute the convex hull that is returned as a triangle mesh. Then, we visualize the convex hull as a red LineSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe349fc8-f5e1-4266-82df-34328c9cc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bunny = o3d.data.BunnyMesh()\n",
    "mesh = o3d.io.read_triangle_mesh(bunny.path)\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "pcl = mesh.sample_points_poisson_disk(number_of_points=2000)\n",
    "hull, _ = pcl.compute_convex_hull()\n",
    "hull_ls = o3d.geometry.LineSet.create_from_triangle_mesh(hull)\n",
    "hull_ls.paint_uniform_color((1, 0, 0))\n",
    "o3d.visualization.draw_geometries([pcl, hull_ls])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5405f33-ead4-4084-a2ea-bee396bb5378",
   "metadata": {},
   "source": [
    "# DBSCAN clustering\n",
    "Given a point cloud from e.g. a depth sensor we want to group local point cloud clusters together. For this purpose, we can use clustering algorithms. Open3D implements DBSCAN [Ester1996] that is a density based clustering algorithm. The algorithm is implemented in cluster_dbscan and requires two parameters: eps defines the distance to neighbors in a cluster and min_points defines the minimum number of points required to form a cluster. The function returns labels, where the label -1 indicates noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d37c1-3eb8-4d2d-a8a2-1e3eb7bd0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "pcd = o3d.io.read_point_cloud(ply_point_cloud.path)\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(\n",
    "        pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=True))\n",
    "\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  zoom=0.455,\n",
    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                  up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37664830-f8c3-48f2-b559-a54e0099a3d7",
   "metadata": {},
   "source": [
    "# Plane segmentation\n",
    "Open3D also supports segmententation of geometric primitives from point clouds using RANSAC. To find the plane with the largest support in the point cloud, we can use segment_plane. The method has three arguments: distance_threshold defines the maximum distance a point can have to an estimated plane to be considered an inlier, ransac_n defines the number of points that are randomly sampled to estimate a plane, and num_iterations defines how often a random plane is sampled and verified. The function then returns the plane as (a,b,c,d) such that for each point (x,y,z) on the plane we have ax + by + cz + d = 0. The function further returns a list of indices of the inlier points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a13a4-a7ca-41c3-a937-aaf6a32fda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_point_cloud = o3d.data.PCDPointCloud()\n",
    "pcd = o3d.io.read_point_cloud(pcd_point_cloud.path)\n",
    "\n",
    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n",
    "                                         ransac_n=3,\n",
    "                                         num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],\n",
    "                                  zoom=0.8,\n",
    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                  up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0615f42-1970-44e9-92da-30a6fe0f03c3",
   "metadata": {},
   "source": [
    "# Planar patch detection\n",
    "In addition to finding the single plane with the largest support, Open3D includes an algorithm which uses a robust statistics-based approach for planar patch detection [ArujoAndOliveira2020]. This algorithm first subdivides the point cloud into smaller chunks (using an octree), then attempts to fit a plane to each chunk. If the plane passes a robust planarity test, then it is accepted. A plane is fitted to a subset of points by taking the median point position and the median point normal and estimating a plane . The robust planarity check consists of two main components. First, the distribution of angles between each point normal and the fitted plane normal is found. If the spread of this distribution is too high (i.e., there is too much variance amongst all of the associated point normals), then the plane is rejected. Second, the distribution of the distances from the fitted plane to each point is computed. If the spread of this distribution is too high, as measured using a coplanarity metric (see Fig. 4 of [ArujoAndOliveira2020]), then the plane is rejected. After an initial set of planes are found, an iterative procedure is used to grow and merge planes into a smaller, stable set of planes. These planes can then be bounded using the 2D convex hull of their associated point sets and planar patches are extracted.\n",
    "\n",
    "To find a list of planar patches in a point cloud, we can use detect_planar_patches. This method can take six arguments: normal_variance_threshold_deg controls the amount of variance allowed amongst the point normals and takes  as its default. Smaller values tends to result in fewer, higher quality planes. coplanarity_deg controls the allowed distribution of point distances from the plane and takes  as its default. Larger values encourage a tighter distribution of points around the fitted plane. outlier_ratio sets the maximum allowable outlier ratio in a fitted planes associated set of points before being rejected and has the default value of 0.75. min_plane_edge_length is used to reject false positives—a planar patch’s largest edge much be greater than this value to be considered a true planar patch. If left at 0, the algorithm defaults to using a value of 1% of the point clouds largest dimension. min_num_points determines how deep the associated octree becomes and how many points must be present when attempting to fit a plane. If left at 0, the algorithm defaults to 0.1% of the number of points in the point cloud. search_param is an instance of geometry::KDTreeSearchParam and defaults to geometry::KDTreeSearchParamKNN. The k nearest neighbors to each point are used when growing and merging planes. Larger values of k tend to produce higher quality patches at the expense of computation. This function then returns a list of detected planar patches, represented as geometry::OrientedBoundingBox objects, with the third column (i.e., ) of R indicating the planar patch normal vector. The extent in the  direction is non-zero so that the OrientedBoundingBox contains the points that contribute to the plane detection. The planar patches can be visualized using the geometry::TriangleMesh::CreateFromOrientedBoundingBox factory function, using the scale parameter to “flatten” the bounding box along the normal, i.e., CreateFromOrientedBoundingBox(obox, scale=[1, 1, 0.0001])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825e1e7-b6c3-4518-b851-a97abd751631",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = o3d.data.PCDPointCloud()\n",
    "pcd = o3d.io.read_point_cloud(dataset.path)\n",
    "assert (pcd.has_normals())\n",
    "\n",
    "# using all defaults\n",
    "oboxes = pcd.detect_planar_patches(\n",
    "    normal_variance_threshold_deg=60,\n",
    "    coplanarity_deg=75,\n",
    "    outlier_ratio=0.75,\n",
    "    min_plane_edge_length=0,\n",
    "    min_num_points=0,\n",
    "    search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "\n",
    "print(\"Detected {} patches\".format(len(oboxes)))\n",
    "\n",
    "geometries = []\n",
    "for obox in oboxes:\n",
    "    mesh = o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(obox, scale=[1, 1, 0.0001])\n",
    "    mesh.paint_uniform_color(obox.color)\n",
    "    geometries.append(mesh)\n",
    "    geometries.append(obox)\n",
    "geometries.append(pcd)\n",
    "\n",
    "o3d.visualization.draw_geometries(geometries,\n",
    "                                  zoom=0.62,\n",
    "                                  front=[0.4361, -0.2632, -0.8605],\n",
    "                                  lookat=[2.4947, 1.7728, 1.5541],\n",
    "                                  up=[-0.1726, -0.9630, 0.2071])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feca265-2c4f-4edf-82d2-05bb5c986e55",
   "metadata": {},
   "source": [
    "# Hidden point removal\n",
    "Imagine you want to render a point cloud from a given view point, but points from the background leak into the foreground because they are not occluded by other points. For this purpose we can apply a hidden point removal algorithm. In Open3D the method by [Katz2007] is implemented that approximates the visibility of a point cloud from a given view without surface reconstruction or normal estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af792f-88fa-4d16-bdbc-438aad433e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Convert mesh to a point cloud and estimate dimensions\")\n",
    "armadillo = o3d.data.ArmadilloMesh()\n",
    "mesh = o3d.io.read_triangle_mesh(armadillo.path)\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "pcd = mesh.sample_points_poisson_disk(5000)\n",
    "diameter = np.linalg.norm(\n",
    "    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34b026-00eb-40e6-a5cb-e8ebcb05a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Define parameters used for hidden_point_removal\")\n",
    "camera = [0, 0, diameter]\n",
    "radius = diameter * 100\n",
    "\n",
    "print(\"Get all points that are visible from given view point\")\n",
    "_, pt_map = pcd.hidden_point_removal(camera, radius)\n",
    "\n",
    "print(\"Visualize result\")\n",
    "pcd = pcd.select_by_index(pt_map)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11cf51-db44-433a-a4ec-46c0879b7e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
